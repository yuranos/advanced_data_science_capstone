{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06c9255e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Deploy a model\n",
    "Let's load our sklearn-flavored model first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b15cbfe9-2733-4c99-b193-095565641bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r best_traditional_model\n",
    "%store -r features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b469a594-4fe9-4da9-a0f1-60960e3b20bd",
   "metadata": {},
   "source": [
    "I'd like to deploy it to AWS SageMaker. I was considering other options, as I know a lot of them since I myself worked in MLOps startup, but afterall it's better to go for one of the most mainstream approaches.\n",
    "AWS has a special ML service, called SageMaker and one of the thing it can do is host a deployed model.\n",
    "All we need is aws account and aws cli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b6d6800-d2a5-4e77-82fa-e4bb81a8847c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws-cli/2.2.11 Python/3.8.8 Linux/5.4.0-131-generic exe/x86_64.ubuntu.20 prompt/off\n"
     ]
    }
   ],
   "source": [
    "!aws --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48ec845a-1447-4993-ada8-d834987ac4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>training_before[Y/N]</th>\n",
       "      <th>body_fat[%]</th>\n",
       "      <th>smoking[Y/N]</th>\n",
       "      <th>alcohol_times_week</th>\n",
       "      <th>education</th>\n",
       "      <th>kids</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>marital_status_married</th>\n",
       "      <th>marital_status_separated</th>\n",
       "      <th>marital_status_single</th>\n",
       "      <th>marital_status_widowed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>39</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  training_before[Y/N]  body_fat[%]  smoking[Y/N]  alcohol_times_week  \\\n",
       "0   37                  True           27         False                   2   \n",
       "1   19                 False           29          True                   2   \n",
       "2   40                  True           28         False                   2   \n",
       "3   42                 False           29         False                   1   \n",
       "4   22                 False           39         False                   0   \n",
       "\n",
       "   education  kids  gender_M  marital_status_married  \\\n",
       "0          0     2         0                       0   \n",
       "1          3     0         0                       0   \n",
       "2          0     2         0                       0   \n",
       "3          1     3         1                       1   \n",
       "4          1     1         0                       0   \n",
       "\n",
       "   marital_status_separated  marital_status_single  marital_status_widowed  \n",
       "0                         0                      0                       0  \n",
       "1                         0                      1                       0  \n",
       "2                         0                      1                       0  \n",
       "3                         0                      0                       0  \n",
       "4                         0                      0                       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6739b06-14c9-4db1-80e1-0065c0c64f0b",
   "metadata": {},
   "source": [
    "To use sklearn model with SageMaker we need to wrap it with joblib library. It's an extra step, but we don't really need to change anything about the model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64eb318-b404-4561-a340-edd71b6adf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arn:aws:iam::076438626459:role/sage-maker-role\n",
    "#s3: sklearn-sage-maker-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2084d7a-b049-44ab-b347-6d1a16465cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing following input: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True, False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "\n",
    "with open('model.joblib', 'wb') as f:\n",
    "    joblib.dump(best_traditional_model,f)\n",
    "\n",
    "\n",
    "with open('model.joblib', 'rb') as f:\n",
    "    predictor = joblib.load(f)\n",
    "\n",
    "print(\"Testing following input: \")\n",
    "\n",
    "predictor.predict(features.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed70cdc-5b08-47ce-9d96-4cd6350d764d",
   "metadata": {},
   "source": [
    "OK, seems there's no problem with joblib. Let's now save that model to pre-created S3 bucket as a tar archive, as that's where SageMaker will load it from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2ed1db4-b527-49ef-91b4-77415df91a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./model.tar.gz to s3://scikit-learn-sage-maker-model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# !tar -czf model.tar.gz model.joblib\n",
    "!aws s3 cp model.tar.gz s3://scikit-learn-sage-maker-model/model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e0b78e-747d-491f-9606-39fee16af38b",
   "metadata": {},
   "source": [
    "Now, most interesting part. There are multiple programmatic ways to interact with SageMaker. A conventional option is to use general AWS client for Python(Boto3), but it's very verbose.\n",
    "Check [boto3-based example](https://towardsdatascience.com/deploying-a-pre-trained-sklearn-model-on-amazon-sagemaker-826a2b5ac0b6).\n",
    "\n",
    "What I find more appealing is to use SageMaker SDK for Python. It allows to avoid a lot of boilerplate.\n",
    "I used [official docs](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html#working-with-existing-model-data-and-training-jobs) for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a185910-a3a9-4874-86a2-1c335c8f3d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8237b769-33ca-4389-81fd-ee4f60666fcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreateModel operation: Could not find model data at s3://sklearn-sage-maker-model/model.tar.gz.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Specify MemorySizeInMB and MaxConcurrency in the serverless config object\u001b[39;00m\n\u001b[1;32m     13\u001b[0m serverless_config \u001b[38;5;241m=\u001b[39m ServerlessInferenceConfig(\n\u001b[1;32m     14\u001b[0m   memory_size_in_mb\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2048\u001b[39m,\n\u001b[1;32m     15\u001b[0m   max_concurrency\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 18\u001b[0m serverless_predictor \u001b[38;5;241m=\u001b[39m \u001b[43msklearn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserverless_inference_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserverless_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/venv39/lib/python3.9/site-packages/sagemaker/model.py:1158\u001b[0m, in \u001b[0;36mModel.deploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, **kwargs)\u001b[0m\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_name, compiled_model_suffix))\n\u001b[0;32m-> 1158\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_sagemaker_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstance_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccelerator_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserverless_inference_config\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m serverless_inference_config_dict \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1163\u001b[0m     serverless_inference_config\u001b[38;5;241m.\u001b[39m_to_request_dict() \u001b[38;5;28;01mif\u001b[39;00m is_serverless \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m )\n\u001b[1;32m   1165\u001b[0m production_variant \u001b[38;5;241m=\u001b[39m sagemaker\u001b[38;5;241m.\u001b[39mproduction_variant(\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m   1167\u001b[0m     instance_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     container_startup_health_check_timeout\u001b[38;5;241m=\u001b[39mcontainer_startup_health_check_timeout,\n\u001b[1;32m   1174\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/venv39/lib/python3.9/site-packages/sagemaker/model.py:685\u001b[0m, in \u001b[0;36mModel._create_sagemaker_model\u001b[0;34m(self, instance_type, accelerator_type, tags, serverless_inference_config)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_sagemaker_session_if_does_not_exist(instance_type)\n\u001b[1;32m    677\u001b[0m create_model_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    678\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    679\u001b[0m     role\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrole,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    683\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[1;32m    684\u001b[0m )\n\u001b[0;32m--> 685\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcreate_model_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/venv39/lib/python3.9/site-packages/sagemaker/session.py:2743\u001b[0m, in \u001b[0;36mSession.create_model\u001b[0;34m(self, name, role, container_defs, vpc_config, enable_network_isolation, primary_container, tags)\u001b[0m\n\u001b[1;32m   2740\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2741\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 2743\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_intercept_create_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_model_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2744\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m name\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/venv39/lib/python3.9/site-packages/sagemaker/session.py:4344\u001b[0m, in \u001b[0;36mSession._intercept_create_request\u001b[0;34m(self, request, create, func_name)\u001b[0m\n\u001b[1;32m   4331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_intercept_create_request\u001b[39m(\n\u001b[1;32m   4332\u001b[0m     \u001b[38;5;28mself\u001b[39m, request: typing\u001b[38;5;241m.\u001b[39mDict, create, func_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m   4333\u001b[0m ):\n\u001b[1;32m   4334\u001b[0m     \u001b[38;5;124;03m\"\"\"This function intercepts the create job request.\u001b[39;00m\n\u001b[1;32m   4335\u001b[0m \n\u001b[1;32m   4336\u001b[0m \u001b[38;5;124;03m    PipelineSession inherits this Session class and will override\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4342\u001b[0m \u001b[38;5;124;03m        func_name (str): the name of the function needed intercepting\u001b[39;00m\n\u001b[1;32m   4343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/venv39/lib/python3.9/site-packages/sagemaker/session.py:2731\u001b[0m, in \u001b[0;36mSession.create_model.<locals>.submit\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m   2729\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreateModel request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(request, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m   2730\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2731\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2732\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2733\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mresponse[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/venv39/lib/python3.9/site-packages/botocore/client.py:530\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[1;32m    529\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/venv39/lib/python3.9/site-packages/botocore/client.py:960\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    958\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m parsed_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    959\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 960\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreateModel operation: Could not find model data at s3://sklearn-sage-maker-model/model.tar.gz."
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "\n",
    "sklearn_model = SKLearnModel(model_data=\"s3://sklearn-sage-maker-model/model.tar.gz\",\n",
    "                             role=\"arn:aws:iam::076438626459:role/sage-maker-role\",\n",
    "                             entry_point=\"entry_point.py\",\n",
    "                             # framework_version=\"1.1.2\",\n",
    "                             framework_version=\"1.0-1\"\n",
    "                            )\n",
    "\n",
    "from sagemaker.serverless import ServerlessInferenceConfig\n",
    "\n",
    "# Specify MemorySizeInMB and MaxConcurrency in the serverless config object\n",
    "serverless_config = ServerlessInferenceConfig(\n",
    "  memory_size_in_mb=2048,\n",
    "  max_concurrency=5,\n",
    ")\n",
    "\n",
    "serverless_predictor = sklearn_model.deploy(serverless_inference_config=serverless_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8034dd3e-da4f-47a0-a92e-a787b189361b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
